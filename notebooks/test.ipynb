{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Cloud Vision API test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import dotenv\n",
    "from pprint import pprint\n",
    "\n",
    "image_path = '../images/001.jpg'\n",
    "#image_path = '/home/tombo/Pictures/test.png'\n",
    "\n",
    "# Load env\n",
    "dotenv.load_dotenv('../.env')\n",
    "#print('Credendtials from environ: {}'.format(\n",
    "#    os.environ.get('GOOGLE_APPLICATION_CREDENTIALS')))\n",
    "\n",
    "# Imports the Google Cloud client library\n",
    "from google.cloud import vision\n",
    "from google.cloud.vision import types\n",
    "\n",
    "# Instantiates a client\n",
    "client = vision.ImageAnnotatorClient()\n",
    "\n",
    "# The name of the image file to annotate\n",
    "#file_name = os.path.join(\n",
    "#    os.path.dirname(__file__),\n",
    "#    'resources/wakeupcat.jpg')\n",
    "\n",
    "# Loads the image into memory\n",
    "with io.open(image_path, 'rb') as image_file:\n",
    "    content = image_file.read()\n",
    "\n",
    "image = types.Image(content=content)\n",
    "\n",
    "# Performs label detection on the image file\n",
    "response = client.label_detection(image=image)\n",
    "labels = response.label_annotations\n",
    "\n",
    "print('Labels:')\n",
    "for label in labels:\n",
    "    print(label.description)\n",
    "\n",
    "pprint(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_text(path):\n",
    "    \"\"\"Detects text in the file.\"\"\"\n",
    "    from google.cloud import vision\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    with io.open(path, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = vision.types.Image(content=content)\n",
    "\n",
    "    response = client.text_detection(image=image)\n",
    "    texts = response.text_annotations\n",
    "    print('Texts:')\n",
    "#\n",
    "    for text in texts:\n",
    "        print('\\n\"{}\"'.format(text.description))\n",
    "#\n",
    "        vertices = (['({},{})'.format(vertex.x, vertex.y)\n",
    "                    for vertex in text.bounding_poly.vertices])\n",
    "#\n",
    "        print('bounds: {}'.format(','.join(vertices)))\n",
    "        print(text.bounding_poly.vertices[0],text.bounding_poly.vertices[2])\n",
    "\n",
    "detect_text(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_text_uri(uri):\n",
    "    \"\"\"Detects text in the file located in Google Cloud Storage or on the Web.\n",
    "    \"\"\"\n",
    "    from google.cloud import vision\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "    image = vision.types.Image()\n",
    "    image.source.image_uri = uri\n",
    "\n",
    "    response = client.text_detection(image=image)\n",
    "    texts = response.text_annotations\n",
    "    print('Texts:')\n",
    "\n",
    "    for text in texts:\n",
    "        print('\\n\"{}\"'.format(text.description))\n",
    "\n",
    "        vertices = (['({},{})'.format(vertex.x, vertex.y)\n",
    "                    for vertex in text.bounding_poly.vertices])\n",
    "\n",
    "        print('bounds: {}'.format(','.join(vertices)))\n",
    "\n",
    "#url = 'http://web.cs.wpi.edu/~claypool/mmsys-dataset/2011/stanford/mvs_images/business_cards/Reference/001.jpg'\n",
    "#url = 'http://web.cs.wpi.edu/~claypool/mmsys-dataset/2011/stanford/mvs_images/business_cards/Reference/015.jpg'\n",
    "\"\"\"\n",
    "Result:\n",
    "\n",
    "8172 Miramar Road,\n",
    "MARGIE SHOOP\n",
    "San Diego, CA 12793\n",
    "Manager\n",
    "\n",
    "Ideal:\n",
    "住所と役職をまとめて欲しかった。左右方向に走査してるから仕方ないといえば仕方ない。\n",
    "8172 Miramar Road,\n",
    "San Diego, CA 12793\n",
    "MARGIE SHOOP\n",
    "Manager\n",
    "\"\"\"\n",
    "\n",
    "#url = 'http://web.cs.wpi.edu/~claypool/mmsys-dataset/2011/stanford/mvs_images/business_cards/Reference/016.jpg'\n",
    "\"\"\"\n",
    "Result:\n",
    "\n",
    "Cambridge Logic Ltd\n",
    "lan Goldsmith\n",
    "Hardware Engineer\n",
    "Address: Queen's Road 125, CB3 4AU,\n",
    "Cambridge, UK\n",
    "Phone: +44 5858 269466\n",
    "E-Mail:ian@cambridgelogic.co.uk\n",
    "\"\"\"\n",
    "\n",
    "#url = 'http://web.cs.wpi.edu/~claypool/mmsys-dataset/2011/stanford/mvs_images/business_cards/Reference/017.jpg'\n",
    "\"\"\"\n",
    "www.circade.com\n",
    "CIRCADE\n",
    "Bernard Desarnauts Founder & CEO\n",
    "Ph. +61 802 4567 | Fax +61 802 4568\n",
    "bdesarnauts@circade.com\n",
    "\"\"\"\n",
    "\n",
    "#url = 'http://web.cs.wpi.edu/~claypool/mmsys-dataset/2011/stanford/mvs_images/business_cards/Reference/026.jpg'\n",
    "\"\"\"\n",
    "Quest\n",
    "Specializing in outplacement and resume writing services\n",
    "8749 Kilbirnie Terrace\n",
    "Brooklyn Pack, MN 55443\n",
    "Phone: 541-513-3755 | Fax: 541-513-3876\n",
    "www.sekelassociates.com\n",
    "\"\"\"\n",
    "\n",
    "#url = 'http://web.cs.wpi.edu/~claypool/mmsys-dataset/2011/stanford/mvs_images/business_cards/Reference/089.jpg'\n",
    "\"\"\"\n",
    "Result:\n",
    "CULTURE\n",
    "otganicfresen yogurt\n",
    "www.culturefrozenyogurt.com\n",
    "\n",
    "Ideal:\n",
    "CULTURE\n",
    "organic frozen yogurt(筆記体だったので難しかったのかも)\n",
    "www.culturefrozenyogurt.com\n",
    "\"\"\"\n",
    "\n",
    "#url = 'http://web.cs.wpi.edu/~claypool/mmsys-dataset/2011/stanford/mvs_images/business_cards/Reference/090.jpg'\n",
    "\"\"\"\n",
    "Result:\n",
    "経済産業省 特許庁\n",
    "特許審査第二部一般機械\n",
    "125m\n",
    "th\n",
    "ANNIVERSARY\n",
    "産業財産権制度125周年\n",
    "審査官\n",
    "產财梅制シンボルマーク\n",
    "山本 健晴\n",
    "T100-8915\n",
    "東京都千代田区霞が関三丁目4番3号\n",
    "携帯:650-468-7208 (米国)\n",
    "080-3450-4412 (日本)\n",
    "E-mai yamamoto-takeharu@jpo. go. jp\n",
    "yamatake2525@gmail.com\n",
    "\n",
    "Ideal:\n",
    "やっぱり走査が横だから、縦にまとまっている情報が複数列あると情報がバラける\n",
    "今回なら役職が\n",
    "経済産業省 特許庁\n",
    "特許審査第二部一般機械\n",
    "審査官\n",
    "のはずなのに、間にロゴの文字の125thとか、産業財産権制度125周年、とかが入り込んできた。\n",
    "このあたりが課題なのかもしれない。\n",
    "\"\"\"\n",
    "\n",
    "#url = 'http://web.cs.wpi.edu/~claypool/mmsys-dataset/2011/stanford/mvs_images/business_cards/Reference/096.jpg'\n",
    "\"\"\"\n",
    "Result:\n",
    "SUN\n",
    "SAT\n",
    "AM\n",
    "PM\n",
    "FRI\n",
    "THURS\n",
    "WED\n",
    "TUES\n",
    "MON\n",
    "AT\n",
    "DATE\n",
    "AVE.\n",
    "W-\n",
    "ECHNICIAN NAME:\n",
    "Apr Oct\n",
    "Nov-March\n",
    "UNIVERSITY\n",
    "NAIL SPA\n",
    "HOURSH0 URS\n",
    "Tues Sat 10am-7pm|| Mon-Sat 10am-7p\n",
    "Sun 10am-5pm\n",
    "Closed on Monday\n",
    "(101\n",
    "NAIL SPA\n",
    "EMBARCADERO RD,\n",
    "RE\n",
    "Sun 10am-50STADIUM\n",
    "MIDDLEFIELD RD\n",
    "ALMA ST\n",
    "650.322.8882| 650.322.8882\n",
    "LajolieNailSpa.comLajolieNailSpa.com\n",
    "ASH ST\n",
    "UNABLE TO KEEP THE APPOINTMENT, A COURTESY OF 24-HOUR ADVANCE NOTICE WILL BE APPRECIATED\n",
    "EL CAMINO R\n",
    "ORNIA AV\n",
    "OREGON EXPY\n",
    "\n",
    "地図などの図が入ってくるとカオス\n",
    "枠などで囲ってある情報はひとまとまりにして、出力してほしいけど、グループ化の概念は無いみたい。\n",
    "隣接する行なら若干、下も読みに行ってるみたいだけど、これでは不十分\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#url = 'http://web.cs.wpi.edu/~claypool/mmsys-dataset/2011/stanford/mvs_images/business_cards/Reference/079.jpg'\n",
    "\"\"\"\n",
    "d.\n",
    "Receppaşa\n",
    "Lamartin Cd\n",
    "Cumhuriyet\n",
    "MUSAFIR\n",
    "Şişli\n",
    "INDIAN\n",
    "Havaş\n",
    "Aydede Cd.\n",
    "$1\n",
    "Bankasi\n",
    "Taksim\n",
    "Gezi\n",
    "Park\n",
    "Tarlabaşı Cd.\n",
    "Taksim\n",
    "istiklal\n",
    "Receppaşa Cd. No:7/C\n",
    "Next to\n",
    "Talimhane Taksim / ISTANBUL\n",
    "Beşiktaş\n",
    "Crystal hotel\n",
    "Tel:(+90) 212 235 27 41\n",
    "Opening Hours:\n",
    "Open everyday:11:00- 23:00\n",
    "Sundays: 14:00-23:00\n",
    "www.musafirindian.com\n",
    "musafir@istanbul.com\n",
    "\n",
    "向きが90度左になっていたので、ところどころ読み取りミスが出てる\n",
    "それでもなんとか読めてしまっているからすごい\n",
    "\"\"\"\n",
    "\n",
    "#url = 'http://web.cs.wpi.edu/~claypool/mmsys-dataset/2011/stanford/mvs_images/business_cards/Reference/071.jpg'\n",
    "\"\"\"\n",
    "Mark Sm\n",
    "Fast Repair\n",
    "2127 El Camino\n",
    "Palo Alto,CA 94\n",
    "Fast Repair\n",
    "CELLULAR REPAIR CENTER\n",
    "Office:650-322-\n",
    "Cell :650-492-8\n",
    "Email:Mark@fastrepair.\n",
    "\"\"\"\n",
    "\n",
    "url = 'http://web.cs.wpi.edu/~claypool/mmsys-dataset/2011/stanford/mvs_images/business_cards/Reference/003.jpg'\n",
    "\"\"\"\n",
    "波浪\n",
    "割烹\n",
    "NAMI NAMI\n",
    "Kappo Dining\n",
    "Shoichi Shiono\n",
    "executive chef\n",
    "240 Castro St.\n",
    "Mountain View, CA 94041\n",
    "Tel.650-964-6990\n",
    "\"\"\"\n",
    "detect_text_uri(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language API test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import dotenv\n",
    "from pprint import pprint\n",
    "\n",
    "# Load env\n",
    "dotenv.load_dotenv('../.env')\n",
    "\n",
    "# Imports the Google Cloud client library\n",
    "from google.cloud import language\n",
    "from google.cloud.language import enums\n",
    "from google.cloud.language import types\n",
    "\n",
    "# Instantiates a client\n",
    "client = language.LanguageServiceClient()\n",
    "\n",
    "# The text to analyze\n",
    "text = u'Hello, world!'\n",
    "document = types.Document(\n",
    "    content=text,\n",
    "    type=enums.Document.Type.PLAIN_TEXT)\n",
    "\n",
    "# Detects the sentiment of the text\n",
    "sentiment = client.analyze_sentiment(document=document).document_sentiment\n",
    "\n",
    "print('Text: {}'.format(text))\n",
    "print('Sentiment: {}, {}'.format(sentiment.score, sentiment.magnitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import six\n",
    "from google.cloud import language\n",
    "from google.cloud.language import enums\n",
    "from google.cloud.language import types\n",
    "\n",
    "text = 'President Kennedy spoke at the White House.'\n",
    "text = \"\"\"\n",
    "波浪\n",
    "割烹\n",
    "NAMI NAMI\n",
    "Kappo Dining\n",
    "Shoichi Shiono\n",
    "executive chef\n",
    "240 Castro St.\n",
    "Mountain View, CA 94041\n",
    "Tel.650-964-6990\n",
    "\"\"\"\n",
    "\n",
    "text = \"\"\"\n",
    "経済産業省 特許庁\n",
    "特許審査第二部一般機械\n",
    "125m\n",
    "th\n",
    "ANNIVERSARY\n",
    "産業財産権制度125周年\n",
    "審査官\n",
    "產财梅制シンボルマーク\n",
    "山本 健晴\n",
    "T100-8915\n",
    "東京都千代田区霞が関三丁目4番3号\n",
    "携帯:650-468-7208 (米国)\n",
    "080-3450-4412 (日本)\n",
    "E-mai yamamoto-takeharu@jpo. go. jp\n",
    "yamatake2525@gmail.com\n",
    "\"\"\"\n",
    "\n",
    "client = language.LanguageServiceClient()\n",
    "\n",
    "if isinstance(text, six.binary_type):\n",
    "    text = text.decode('utf-8')\n",
    "\n",
    "# Instantiates a plain text document.\n",
    "document = types.Document(\n",
    "    content=text,\n",
    "    type=enums.Document.Type.PLAIN_TEXT)\n",
    "\n",
    "# Detects entities in the document. You can also analyze HTML with:\n",
    "#   document.type == enums.Document.Type.HTML\n",
    "entities = client.analyze_entities(document).entities\n",
    "\n",
    "for entity in entities:\n",
    "    entity_type = enums.Entity.Type(entity.type)\n",
    "    print('=' * 20)\n",
    "    print(u'{:<16}: {}'.format('name', entity.name))\n",
    "    print(u'{:<16}: {}'.format('type', entity_type.name))\n",
    "    print(u'{:<16}: {}'.format('salience', entity.salience))\n",
    "    print(u'{:<16}: {}'.format('wikipedia_url',\n",
    "          entity.metadata.get('wikipedia_url', '-')))\n",
    "    print(u'{:<16}: {}'.format('mid', entity.metadata.get('mid', '-')))\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import six\n",
    "from google.cloud import language\n",
    "from google.cloud.language import enums\n",
    "from google.cloud.language import types\n",
    "\n",
    "required_entities = {'ORGANIZATION':'','PERSON':'','LOCATION':'','ADDRESS':'','PHONE_NUMBER':'',}\n",
    "\n",
    "def extract_entities(text,required_entities):\n",
    "    client = language.LanguageServiceClient()\n",
    "    \n",
    "    if isinstance(text, six.binary_type):\n",
    "        text = text.decode('utf-8')\n",
    "    \n",
    "    # Instantiates a plain text document.\n",
    "    document = types.Document(\n",
    "        content=text,\n",
    "        type=enums.Document.Type.PLAIN_TEXT)\n",
    "    \n",
    "    # Detects entities in the document. You can also analyze HTML with:\n",
    "    #   document.type == enums.Document.Type.HTML\n",
    "    entities = client.analyze_entities(document).entities\n",
    "    \n",
    "    for entity in entities:\n",
    "        entity_type = enums.Entity.Type(entity.type)\n",
    "        if entity_type.name in required_entities:\n",
    "            #print(entity.name)\n",
    "            required_entities[entity_type.name] += entity.name\n",
    "        #print('=' * 20)\n",
    "        #print(u'{:<16}: {}'.format('name', entity.name))\n",
    "        #print(u'{:<16}: {}'.format('type', entity_type.name))\n",
    "        #print(u'{:<16}: {}'.format('salience', entity.salience))\n",
    "        #print(u'{:<16}: {}'.format('wikipedia_url',\n",
    "        #      entity.metadata.get('wikipedia_url', '-')))\n",
    "        #print(u'{:<16}: {}'.format('mid', entity.metadata.get('mid', '-')))\n",
    "    pprint(required_entities)\n",
    "extract_entities(text,required_entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# opencv overlay test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "image_path = '../images/001.jpg'\n",
    "alpha = 0.3\n",
    "image = cv2.imread(image_path)\n",
    "overlay = image.copy()\n",
    "output = image.copy()\n",
    "\n",
    "cv2.rectangle(overlay,(10,20),(30,40),(0,255,0),-1)\n",
    "cv2.rectangle(overlay,(10,20),(70,79),(0,255,0),-1)\n",
    "cv2.addWeighted(overlay, alpha, output, 1 - alpha,0, output)\n",
    "cv2.imwrite('../images/overlay_test.jpg',output)\n",
    "cv2.imwrite('../images/overlay.jpg',overlay)\n",
    "#cv2.imshow('output',output)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# json test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
